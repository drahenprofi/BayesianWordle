{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9a5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35558123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordleCritic:\n",
    "    \"\"\"\n",
    "    Klasse, die ein Wordle Spiel repräsentiert\n",
    "    Bekommt ein Startwort zugewiesen und bewertet Vorschläge im Stile eines Wordle Spiels\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, word):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        word: string\n",
    "            Das zu erratende Wort\n",
    "        \"\"\"\n",
    "        self.word = word\n",
    "        \n",
    "    \"\"\"\n",
    "    Bewertet einen Vorschlag und gibt das Ergebnis im Stile eines Wordle-Spiels zurück (grau, gelb, grün)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    suggestion: string\n",
    "        Der Vorschlag, der bewertet werden soll\n",
    "    \"\"\"\n",
    "    def judge(self, suggestion):\n",
    "        result = [\"gray\" for i in range(len(self.word))]\n",
    "        \n",
    "        for index, letter in enumerate(suggestion):\n",
    "            if letter == self.word[index]:\n",
    "                result[index] = \"green\"\n",
    "            elif letter in self.word:\n",
    "                result[index] = \"yellow\"\n",
    "                \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806e5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordlePlayer:\n",
    "    \"\"\"\n",
    "    Klasse, die einen Wordle-Spieler repräsentiert\n",
    "    Generiert einen möglichen nächsten Vorschlag, basierend auf dem bereits bekannten Informationen\n",
    "    Die Vorschläge werden auf Basis eines Bayes'schen Netzes mit der Bibliothek pgmpy generiert\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, words_file, model):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        words_file: string\n",
    "            Name der Wortliste (selber Name für CSV und JSON Datei)\n",
    "        model: BayesianNetwork\n",
    "            Das Bayes'sche Netzwerk von pgmpy\n",
    "        \"\"\"\n",
    "        \n",
    "        self.words_pd = pd.read_csv(words_file + \".csv\")\n",
    "        \n",
    "        with open(words_file + \".json\", \"r\") as f:\n",
    "            self.words_list = json.load(f) \n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "        self.model.fit(self.words_pd, estimator=MaximumLikelihoodEstimator)\n",
    "        self.infer = VariableElimination(self.model)\n",
    "        \n",
    "    \"\"\"\n",
    "    Setzt ein Wort aus den bereits bekannten Informationen und der Rückgabe der Veriable Elimination zusammen\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    suggestion: dict\n",
    "        Das Ergebnis der Variable Elimination auf dem Bayes'schen Netz\n",
    "    evidence: dict\n",
    "        Die bereits bekannten Zustände\n",
    "    \"\"\"\n",
    "    def get_suggestion_word(self, suggestion, evidence):\n",
    "        word = [\"\", \"\", \"\", \"\", \"\"]\n",
    "\n",
    "        if \"first\" in evidence:\n",
    "            word[0] = evidence[\"first\"]\n",
    "        else: \n",
    "            word[0] = suggestion[\"first\"]\n",
    "\n",
    "        if \"second\" in evidence:\n",
    "            word[1] = evidence[\"second\"]\n",
    "        else:\n",
    "            word[1] = suggestion[\"second\"]\n",
    "\n",
    "        if \"third\" in evidence:\n",
    "            word[2] = evidence[\"third\"]\n",
    "        else:\n",
    "            word[2] = suggestion[\"third\"]\n",
    "\n",
    "        if \"forth\" in evidence:\n",
    "            word[3] = evidence[\"forth\"]\n",
    "        else:\n",
    "            word[3] = suggestion[\"forth\"]\n",
    "\n",
    "        if \"fifth\" in evidence:\n",
    "            word[4] = evidence[\"fifth\"]\n",
    "        else:\n",
    "            word[4] = suggestion[\"fifth\"]\n",
    "\n",
    "        return word\n",
    "\n",
    "    \"\"\"\n",
    "    Überprüft, ob ein Wort ein valider Vorschlag ist\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    must_contain: list, optional\n",
    "        Die Buchstaben, welche im Wort enthalten sein müssen (gelb markiert)\n",
    "    must_not_contain: list, optional\n",
    "        Die Buchstaben, welche nicht im Wort enthalten sein dürfen (grau markiert)\n",
    "    must_not_contain_at: dict, optional\n",
    "        Jeweils fünf Listen, mit den Buchstaben die an der jeweiligen Position nicht vorhanden sein dürfen \n",
    "        (z.B. {\"first\": [\"A\", \"B\"], \"second\": [\"S\"], \"third\": [], \"forth\": [], \"fifth\": []})\n",
    "    \"\"\"\n",
    "    def word_is_valid(self, word, must_contain=[], must_not_contain=[], must_not_contain_at={}):\n",
    "        if \"\".join(str(char) for char in word) in self.words_list:\n",
    "\n",
    "            for letter in must_contain:\n",
    "                if not letter in word:\n",
    "                    return False\n",
    "\n",
    "            for letter in must_not_contain:\n",
    "                if letter in word:\n",
    "                    return False\n",
    "\n",
    "            if \"first\" in must_not_contain_at and word[0] in must_not_contain_at[\"first\"]:\n",
    "                return False\n",
    "            \n",
    "            if \"second\" in must_not_contain_at and word[1] in must_not_contain_at[\"second\"]:\n",
    "                return False\n",
    "\n",
    "            if \"third\" in must_not_contain_at and word[2] in must_not_contain_at[\"third\"]:\n",
    "                return False\n",
    "\n",
    "            if \"forth\" in must_not_contain_at and word[3] in must_not_contain_at[\"forth\"]:\n",
    "                return False\n",
    "\n",
    "            if \"fifth\" in must_not_contain_at and word[4] in must_not_contain_at[\"fifth\"]:\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    \"\"\"\n",
    "    Genereriert einen neuen Vorschlag, basierend auf: \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    variables: list\n",
    "        Die Variablen an denen die Buchstaben noch unbekannt und gesucht sind (z.B. [\"first\", \"second\"])\n",
    "    evidence: dict\n",
    "        Die bereits bekannten Variablen und deren Zustand (z.B. {\"first\": \"A\", \"second\": \"S\"})\n",
    "    must_contain: list, optional\n",
    "        Die Buchstaben, welche im Wort enthalten sein müssen (gelb markiert)\n",
    "    must_not_contain: list, optional\n",
    "        Die Buchstaben, welche nicht im Wort enthalten sein dürfen (grau markiert)\n",
    "    must_not_contain_at: dict, optional\n",
    "        Jeweils fünf Listen, mit den Buchstaben die an der jeweiligen Position nicht vorhanden sein dürfen \n",
    "        (z.B. {\"first\": [\"A\", \"B\"], \"second\": [\"S\"], \"third\": [], \"forth\": [], \"fifth\": []})\n",
    "    \"\"\"\n",
    "    def get_suggestion(self, variables, evidence, must_contain=[], must_not_contain=[], must_not_contain_at=[]):\n",
    "        q = self.infer.query(variables, evidence=evidence, show_progress=False)\n",
    "\n",
    "        count_predictions = len(q.values.flatten()[q.values.flatten() != 0])\n",
    "        max_value_indices = (-q.values.flatten()).argsort()[:count_predictions]\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for max_value_index in max_value_indices:\n",
    "            indices = np.unravel_index(max_value_index, q.values.shape)\n",
    "\n",
    "            suggestion = {}\n",
    "\n",
    "            for index, variable in enumerate(q.variables):\n",
    "                suggestion[variable] = self.model.get_cpds(variable).state_names[variable][indices[index]]\n",
    "\n",
    "            word = self.get_suggestion_word(suggestion, evidence)\n",
    "\n",
    "            if self.word_is_valid(word, must_contain, must_not_contain, must_not_contain_at):\n",
    "                #result.append(word)\n",
    "                return word\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \"\"\"Generiert den ersten Vorschlag\"\"\"\n",
    "    def get_first_suggestion(self):\n",
    "        first = self.infer.map_query([\"first\"], show_progress=False)[\"first\"]\n",
    "        second = self.infer.map_query([\"second\"], evidence={\"first\": first}, show_progress=False)[\"second\"]\n",
    "        third = self.infer.map_query([\"third\"], evidence={\"first\": first, \"second\": second}, show_progress=False)[\"third\"]\n",
    "        forth = self.infer.map_query([\"forth\"], evidence={\"first\": first, \"second\": second, \"third\": third}, show_progress=False)[\"forth\"]\n",
    "        fifth = self.infer.map_query([\"fifth\"], evidence={\"first\": first, \"second\": second, \"third\": third, \"forth\": forth}, show_progress=False)[\"fifth\"]\n",
    "\n",
    "        if self.word_is_valid(\"\".join([first,second,third,forth,fifth])):\n",
    "            return \"\".join[first,second,third,forth,fifth]\n",
    "        elif len(self.words_pd[\n",
    "                (self.words_pd[\"first\"] == first) & \n",
    "                (self.words_pd[\"second\"] == second) & \n",
    "                (self.words_pd[\"third\"] == third) & \n",
    "                (self.words_pd[\"forth\"] == forth)]) > 0:\n",
    "            return self.words_pd[\n",
    "                (self.words_pd[\"first\"] == first) & \n",
    "                (self.words_pd[\"second\"] == second) & \n",
    "                (self.words_pd[\"third\"] == third) & \n",
    "                (self.words_pd[\"forth\"] == forth)].values[0]\n",
    "        else:\n",
    "            return self.words_pd[\n",
    "                (self.words_pd[\"first\"] == first) & \n",
    "                (self.words_pd[\"second\"] == second) & \n",
    "                (self.words_pd[\"third\"] == third)].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2a8f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLIRT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neues Wordle-Spiel mit einem zufälligen Wort aus der Wortliste\n",
    "\"\"\"\n",
    "\n",
    "with open(\"words.json\", \"r\") as f:\n",
    "    words = json.load(f)\n",
    "\n",
    "word = random.choice(words)\n",
    "\n",
    "critic = WordleCritic(word)\n",
    "\n",
    "print(critic.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8748d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: SABOR\n",
      "['gray', 'gray', 'gray', 'gray', 'yellow']\n",
      "\n",
      "2: REINE\n",
      "['yellow', 'gray', 'green', 'gray', 'gray']\n",
      "\n",
      "3: TRIFT\n",
      "['yellow', 'yellow', 'green', 'yellow', 'green']\n",
      "\n",
      "4: FLIRT\n",
      "['green', 'green', 'green', 'green', 'green']\n",
      "\n",
      "The word you are looking for is FLIRT!\n",
      "Found it in 4 tries!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Selbstspielendes Wordle-Spiel\n",
    "Das erstellte Player-Objekt verarbeitet die Informationen, die der Critic liefert und generiert so lange neue \n",
    "Vorschläge, bis das zu erratende Wort gefunden ist\n",
    "\"\"\"\n",
    "\n",
    "model = BayesianNetwork([\n",
    "    (\"first\", \"second\"), \n",
    "    (\"third\", \"second\"), \n",
    "    (\"third\", \"forth\"), \n",
    "    (\"fifth\", \"forth\")\n",
    "])\n",
    "\n",
    "player = WordlePlayer(\"words\", model)\n",
    "\n",
    "suggestion = player.get_first_suggestion()\n",
    "\n",
    "known_information = {\n",
    "    \"variables\":set([]), \n",
    "    \"evidence\":{}, \n",
    "    \"must_contain\":set([]), \n",
    "    \"must_not_contain\":set([]),\n",
    "    \"must_not_contain_at\":{\n",
    "        \"first\":set([]), \n",
    "        \"second\":set([]), \n",
    "        \"third\":set([]),\n",
    "        \"forth\":set([]),\n",
    "        \"fifth\":set([])\n",
    "    }\n",
    "}\n",
    "\n",
    "tries = 0\n",
    "\n",
    "while True:\n",
    "    evidences = critic.judge(suggestion)\n",
    "    tries += 1\n",
    "    \n",
    "    print(str(tries) + \": \" + \"\".join(suggestion))\n",
    "    print(evidences)\n",
    "    print()\n",
    "    \n",
    "    if evidences[0] == \"green\" and evidences[1] == \"green\" and evidences[2] == \"green\" and evidences[3] == \"green\" and evidences[4] == \"green\":\n",
    "        break\n",
    "    \n",
    "    if evidences[0] == \"gray\":\n",
    "        known_information[\"variables\"].add(\"first\")\n",
    "        known_information[\"must_not_contain\"].add(suggestion[0])\n",
    "    elif evidences[0] == \"yellow\":\n",
    "        known_information[\"variables\"].add(\"first\")\n",
    "        known_information[\"must_contain\"].add(suggestion[0])\n",
    "        known_information[\"must_not_contain_at\"][\"first\"].add(suggestion[0])\n",
    "    elif evidences[0] == \"green\":\n",
    "        known_information[\"variables\"].discard(\"first\")\n",
    "        known_information[\"evidence\"][\"first\"] = suggestion[0]\n",
    "\n",
    "    if evidences[1] == \"gray\":\n",
    "        known_information[\"variables\"].add(\"second\")\n",
    "        known_information[\"must_not_contain\"].add(suggestion[1])\n",
    "    elif evidences[1] == \"yellow\":\n",
    "        known_information[\"variables\"].add(\"second\")\n",
    "        known_information[\"must_contain\"].add(suggestion[1])\n",
    "        known_information[\"must_not_contain_at\"][\"second\"].add(suggestion[1])\n",
    "    elif evidences[1] == \"green\":\n",
    "        known_information[\"variables\"].discard(\"second\")\n",
    "        known_information[\"evidence\"][\"second\"] = suggestion[1]\n",
    "\n",
    "    if evidences[2] == \"gray\":\n",
    "        known_information[\"variables\"].add(\"third\")\n",
    "        known_information[\"must_not_contain\"].add(suggestion[2])\n",
    "    elif evidences[2] == \"yellow\":\n",
    "        known_information[\"variables\"].add(\"third\")\n",
    "        known_information[\"must_contain\"].add(suggestion[2])\n",
    "        known_information[\"must_not_contain_at\"][\"third\"].add(suggestion[2])\n",
    "    elif evidences[2] == \"green\":\n",
    "        known_information[\"variables\"].discard(\"third\")\n",
    "        known_information[\"evidence\"][\"third\"] = suggestion[2]\n",
    "\n",
    "    if evidences[3] == \"gray\":\n",
    "        known_information[\"variables\"].add(\"forth\")\n",
    "        known_information[\"must_not_contain\"].add(suggestion[3])\n",
    "    elif evidences[3] == \"yellow\":\n",
    "        known_information[\"variables\"].add(\"forth\")\n",
    "        known_information[\"must_contain\"].add(suggestion[3])\n",
    "        known_information[\"must_not_contain_at\"][\"forth\"].add(suggestion[3])\n",
    "    elif evidences[3] == \"green\":\n",
    "        known_information[\"variables\"].discard(\"forth\")\n",
    "        known_information[\"evidence\"][\"forth\"] = suggestion[3]\n",
    "\n",
    "    if evidences[4] == \"gray\":\n",
    "        known_information[\"variables\"].add(\"fifth\")\n",
    "        known_information[\"must_not_contain\"].add(suggestion[4])\n",
    "    elif evidences[4] == \"yellow\":\n",
    "        known_information[\"variables\"].add(\"fifth\")\n",
    "        known_information[\"must_contain\"].add(suggestion[4])\n",
    "        known_information[\"must_not_contain_at\"][\"fifth\"].add(suggestion[4])\n",
    "    elif evidences[4] == \"green\":\n",
    "        known_information[\"variables\"].discard(\"fifth\")\n",
    "        known_information[\"evidence\"][\"fifth\"] = suggestion[4]\n",
    "\n",
    "    suggestion = player.get_suggestion(\n",
    "        known_information[\"variables\"], \n",
    "        known_information[\"evidence\"],\n",
    "        known_information[\"must_contain\"],\n",
    "        known_information[\"must_not_contain\"],\n",
    "        known_information[\"must_not_contain_at\"]\n",
    "    )\n",
    "    \n",
    "print(\"The word you are looking for is \" + \"\".join(suggestion) + \"!\")\n",
    "print(\"Found it in \" + str(tries) + \" tries!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
