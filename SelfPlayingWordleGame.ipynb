{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a9a5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35558123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordleCritic:\n",
    "    def __init__(self, words_file):\n",
    "        with open(words_file + \".json\", \"r\") as f:\n",
    "            words = json.load(f)\n",
    "        \n",
    "        self.word = random.choice(words)\n",
    "        \n",
    "    def judge(self, suggestion):\n",
    "        result = [\"gray\" for i in range(len(self.word))]\n",
    "        \n",
    "        for index, letter in enumerate(suggestion):\n",
    "            if letter == self.word[index]:\n",
    "                result[index] = \"green\"\n",
    "            elif letter in self.word:\n",
    "                result[index] = \"yellow\"\n",
    "                \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806e5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordlePlayer:\n",
    "    def __init__(self, words_file):\n",
    "        self.words_pd = pd.read_csv(words_file + \".csv\")\n",
    "        \n",
    "        with open(words_file + \".json\", \"r\") as f:\n",
    "            self.words_list = json.load(f) \n",
    "        \n",
    "        self.model = BayesianNetwork([\n",
    "            (\"first\", \"second\"), \n",
    "            (\"third\", \"second\"), \n",
    "            (\"third\", \"forth\"), \n",
    "            (\"fifth\", \"forth\")\n",
    "        ])\n",
    "\n",
    "        self.model.fit(self.words_pd, estimator=MaximumLikelihoodEstimator)\n",
    "        self.infer = VariableElimination(self.model)\n",
    "        \n",
    "    def get_suggestion_word(self, suggestion, evidence):\n",
    "        word = [\"\", \"\", \"\", \"\", \"\"]\n",
    "\n",
    "        if \"first\" in evidence:\n",
    "            word[0] = evidence[\"first\"]\n",
    "        else: \n",
    "            word[0] = suggestion[\"first\"]\n",
    "\n",
    "        if \"second\" in evidence:\n",
    "            word[1] = evidence[\"second\"]\n",
    "        else:\n",
    "            word[1] = suggestion[\"second\"]\n",
    "\n",
    "        if \"third\" in evidence:\n",
    "            word[2] = evidence[\"third\"]\n",
    "        else:\n",
    "            word[2] = suggestion[\"third\"]\n",
    "\n",
    "        if \"forth\" in evidence:\n",
    "            word[3] = evidence[\"forth\"]\n",
    "        else:\n",
    "            word[3] = suggestion[\"forth\"]\n",
    "\n",
    "        if \"fifth\" in evidence:\n",
    "            word[4] = evidence[\"fifth\"]\n",
    "        else:\n",
    "            word[4] = suggestion[\"fifth\"]\n",
    "\n",
    "        return word\n",
    "\n",
    "    def word_is_valid(self, word, must_contain=[], must_not_contain=[], must_not_contain_at={}):\n",
    "        if \"\".join(str(char) for char in word) in self.words_list:\n",
    "\n",
    "            for letter in must_contain:\n",
    "                if not letter in word:\n",
    "                    return False\n",
    "\n",
    "            for letter in must_not_contain:\n",
    "                if letter in word:\n",
    "                    return False\n",
    "\n",
    "            if \"first\" in must_not_contain_at and word[0] in must_not_contain_at[\"first\"]:\n",
    "                return False\n",
    "            \n",
    "            if \"second\" in must_not_contain_at and word[1] in must_not_contain_at[\"second\"]:\n",
    "                return False\n",
    "\n",
    "            if \"third\" in must_not_contain_at and word[2] in must_not_contain_at[\"third\"]:\n",
    "                return False\n",
    "\n",
    "            if \"forth\" in must_not_contain_at and word[3] in must_not_contain_at[\"forth\"]:\n",
    "                return False\n",
    "\n",
    "            if \"fifth\" in must_not_contain_at and word[4] in must_not_contain_at[\"fifth\"]:\n",
    "                return False\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_suggestion(self, variables, evidence, must_contain=[], must_not_contain=[], must_not_contain_at=[]):\n",
    "        q = self.infer.query(variables, evidence=evidence, show_progress=False)\n",
    "\n",
    "        count_predictions = len(q.values.flatten()[q.values.flatten() != 0])\n",
    "        max_value_indices = (-q.values.flatten()).argsort()[:count_predictions]\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for max_value_index in max_value_indices:\n",
    "            indices = np.unravel_index(max_value_index, q.values.shape)\n",
    "\n",
    "            suggestion = {}\n",
    "\n",
    "            for index, variable in enumerate(q.variables):\n",
    "                suggestion[variable] = self.model.get_cpds(variable).state_names[variable][indices[index]]\n",
    "\n",
    "            word = self.get_suggestion_word(suggestion, evidence)\n",
    "\n",
    "            if self.word_is_valid(word, must_contain, must_not_contain, must_not_contain_at):\n",
    "                #result.append(word)\n",
    "                return word\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def get_first_suggestion(self):\n",
    "        first = self.infer.map_query([\"first\"], show_progress=False)[\"first\"]\n",
    "        second = self.infer.map_query([\"second\"], evidence={\"first\": first}, show_progress=False)[\"second\"]\n",
    "        third = self.infer.map_query([\"third\"], evidence={\"first\": first, \"second\": second}, show_progress=False)[\"third\"]\n",
    "        forth = self.infer.map_query([\"forth\"], evidence={\"first\": first, \"second\": second, \"third\": third}, show_progress=False)[\"forth\"]\n",
    "        fifth = self.infer.map_query([\"fifth\"], evidence={\"first\": first, \"second\": second, \"third\": third, \"forth\": forth}, show_progress=False)[\"fifth\"]\n",
    "\n",
    "        if self.word_is_valid(\"\".join([first,second,third,forth,fifth])):\n",
    "            return \"\".join[first,second,third,forth,fifth]\n",
    "        elif len(self.words_pd[\n",
    "                (self.words_pd[\"first\"] == first) & \n",
    "                (self.words_pd[\"second\"] == second) & \n",
    "                (self.words_pd[\"third\"] == third) & \n",
    "                (self.words_pd[\"forth\"] == forth)]) > 0:\n",
    "            return self.words_pd[\n",
    "                (self.words_pd[\"first\"] == first) & \n",
    "                (self.words_pd[\"second\"] == second) & \n",
    "                (self.words_pd[\"third\"] == third) & \n",
    "                (self.words_pd[\"forth\"] == forth)].values[0]\n",
    "        else:\n",
    "            return self.words_pd[\n",
    "                (self.words_pd[\"first\"] == first) & \n",
    "                (self.words_pd[\"second\"] == second) & \n",
    "                (self.words_pd[\"third\"] == third)].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e2a8f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUSE\n"
     ]
    }
   ],
   "source": [
    "critic = WordleCritic(\"wordle-at-words\")\n",
    "\n",
    "print(critic.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8748d184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: SABOR\n",
      "['yellow', 'gray', 'gray', 'gray', 'gray']\n",
      "\n",
      "2: LEINS\n",
      "['yellow', 'yellow', 'gray', 'gray', 'yellow']\n",
      "\n",
      "3: FLUSE\n",
      "['green', 'green', 'green', 'green', 'green']\n",
      "\n",
      "The word you are looking for is FLUSE!\n",
      "Found it in 3 tries!\n"
     ]
    }
   ],
   "source": [
    "player = WordlePlayer(\"wordle-at-words\")\n",
    "\n",
    "suggestion = player.get_first_suggestion()\n",
    "\n",
    "new_input = {\n",
    "    \"variables\":set([]), \n",
    "    \"evidence\":{}, \n",
    "    \"must_contain\":set([]), \n",
    "    \"must_not_contain\":set([]),\n",
    "    \"must_not_contain_at\":{\n",
    "        \"first\":set([]), \n",
    "        \"second\":set([]), \n",
    "        \"third\":set([]),\n",
    "        \"forth\":set([]),\n",
    "        \"fifth\":set([])\n",
    "    }\n",
    "}\n",
    "\n",
    "tries = 0\n",
    "\n",
    "while True:\n",
    "    evidences = critic.judge(suggestion)\n",
    "    tries += 1\n",
    "    \n",
    "    print(str(tries) + \": \" + \"\".join(suggestion))\n",
    "    print(evidences)\n",
    "    print()\n",
    "    \n",
    "    if evidences[0] == \"green\" and evidences[1] == \"green\" and evidences[2] == \"green\" and evidences[3] == \"green\" and evidences[4] == \"green\":\n",
    "        break\n",
    "    \n",
    "    if evidences[0] == \"gray\":\n",
    "        new_input[\"variables\"].add(\"first\")\n",
    "        new_input[\"must_not_contain\"].add(suggestion[0])\n",
    "    elif evidences[0] == \"yellow\":\n",
    "        new_input[\"variables\"].add(\"first\")\n",
    "        new_input[\"must_contain\"].add(suggestion[0])\n",
    "        new_input[\"must_not_contain_at\"][\"first\"].add(suggestion[0])\n",
    "    elif evidences[0] == \"green\":\n",
    "        new_input[\"variables\"].discard(\"first\")\n",
    "        new_input[\"evidence\"][\"first\"] = suggestion[0]\n",
    "\n",
    "    if evidences[1] == \"gray\":\n",
    "        new_input[\"variables\"].add(\"second\")\n",
    "        new_input[\"must_not_contain\"].add(suggestion[1])\n",
    "    elif evidences[1] == \"yellow\":\n",
    "        new_input[\"variables\"].add(\"second\")\n",
    "        new_input[\"must_contain\"].add(suggestion[1])\n",
    "        new_input[\"must_not_contain_at\"][\"second\"].add(suggestion[1])\n",
    "    elif evidences[1] == \"green\":\n",
    "        new_input[\"variables\"].discard(\"second\")\n",
    "        new_input[\"evidence\"][\"second\"] = suggestion[1]\n",
    "\n",
    "    if evidences[2] == \"gray\":\n",
    "        new_input[\"variables\"].add(\"third\")\n",
    "        new_input[\"must_not_contain\"].add(suggestion[2])\n",
    "    elif evidences[2] == \"yellow\":\n",
    "        new_input[\"variables\"].add(\"third\")\n",
    "        new_input[\"must_contain\"].add(suggestion[2])\n",
    "        new_input[\"must_not_contain_at\"][\"third\"].add(suggestion[2])\n",
    "    elif evidences[2] == \"green\":\n",
    "        new_input[\"variables\"].discard(\"third\")\n",
    "        new_input[\"evidence\"][\"third\"] = suggestion[2]\n",
    "\n",
    "    if evidences[3] == \"gray\":\n",
    "        new_input[\"variables\"].add(\"forth\")\n",
    "        new_input[\"must_not_contain\"].add(suggestion[3])\n",
    "    elif evidences[3] == \"yellow\":\n",
    "        new_input[\"variables\"].add(\"forth\")\n",
    "        new_input[\"must_contain\"].add(suggestion[3])\n",
    "        new_input[\"must_not_contain_at\"][\"forth\"].add(suggestion[3])\n",
    "    elif evidences[3] == \"green\":\n",
    "        new_input[\"variables\"].discard(\"forth\")\n",
    "        new_input[\"evidence\"][\"forth\"] = suggestion[3]\n",
    "\n",
    "    if evidences[4] == \"gray\":\n",
    "        new_input[\"variables\"].add(\"fifth\")\n",
    "        new_input[\"must_not_contain\"].add(suggestion[4])\n",
    "    elif evidences[4] == \"yellow\":\n",
    "        new_input[\"variables\"].add(\"fifth\")\n",
    "        new_input[\"must_contain\"].add(suggestion[4])\n",
    "        new_input[\"must_not_contain_at\"][\"fifth\"].add(suggestion[4])\n",
    "    elif evidences[4] == \"green\":\n",
    "        new_input[\"variables\"].discard(\"fifth\")\n",
    "        new_input[\"evidence\"][\"fifth\"] = suggestion[4]\n",
    "\n",
    "    suggestion = player.get_suggestion(\n",
    "        new_input[\"variables\"], \n",
    "        new_input[\"evidence\"],\n",
    "        new_input[\"must_contain\"],\n",
    "        new_input[\"must_not_contain\"],\n",
    "        new_input[\"must_not_contain_at\"]\n",
    "    )\n",
    "    \n",
    "print(\"The word you are looking for is \" + \"\".join(suggestion) + \"!\")\n",
    "print(\"Found it in \" + str(tries) + \" tries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904b9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
