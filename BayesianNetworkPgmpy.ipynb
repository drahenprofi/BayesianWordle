{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef55071",
   "metadata": {},
   "source": [
    "## Bayes'sches Netz zur Bestimmung des nächsten Vorschlags mit höchster Wahrscheinlichkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2871908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "import math\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c82318",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"words.csv\")\n",
    "\n",
    "model = BayesianNetwork([\n",
    "    (\"first\", \"second\"), \n",
    "    (\"third\", \"second\"), \n",
    "    (\"third\", \"forth\"), \n",
    "    (\"fifth\", \"forth\")])\n",
    "\n",
    "model.fit(words, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "infer = VariableElimination(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08854ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestion_word(suggestion, evidence):\n",
    "    word = [\"\", \"\", \"\", \"\", \"\"]\n",
    "    \n",
    "    if \"first\" in evidence:\n",
    "        word[0] = evidence[\"first\"]\n",
    "    else: \n",
    "        word[0] = suggestion[\"first\"]\n",
    "        \n",
    "    if \"second\" in evidence:\n",
    "        word[1] = evidence[\"second\"]\n",
    "    else:\n",
    "        word[1] = suggestion[\"second\"]\n",
    "    \n",
    "    if \"third\" in evidence:\n",
    "        word[2] = evidence[\"third\"]\n",
    "    else:\n",
    "        word[2] = suggestion[\"third\"]\n",
    "    \n",
    "    if \"forth\" in evidence:\n",
    "        word[3] = evidence[\"forth\"]\n",
    "    else:\n",
    "        word[3] = suggestion[\"forth\"]\n",
    "    \n",
    "    if \"fifth\" in evidence:\n",
    "        word[4] = evidence[\"fifth\"]\n",
    "    else:\n",
    "        word[4] = suggestion[\"fifth\"]\n",
    "        \n",
    "    return word\n",
    "\n",
    "def word_is_valid(word, words, must_contain=[], must_not_contain=[], must_not_contain_at={}):\n",
    "    if \"\".join(str(char) for char in word) in words:\n",
    "        for letter in must_contain:\n",
    "            if not letter in word:\n",
    "                return False\n",
    "            \n",
    "        for letter in must_not_contain:\n",
    "            if letter in word:\n",
    "                return False\n",
    "        \n",
    "        if \"first\" in must_not_contain_at and word[0] in must_not_contain_at[\"first\"]:\n",
    "            return False\n",
    "                \n",
    "        if \"second\" in must_not_contain_at and word[1] in must_not_contain_at[\"second\"]:\n",
    "            return False\n",
    "                \n",
    "        if \"third\" in must_not_contain_at and word[2] in must_not_contain_at[\"third\"]:\n",
    "            return False\n",
    "                \n",
    "        if \"forth\" in must_not_contain_at and word[3] in must_not_contain_at[\"forth\"]:\n",
    "            return False\n",
    "                \n",
    "        if \"fifth\" in must_not_contain_at and word[4] in must_not_contain_at[\"fifth\"]:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_suggestion(variables, evidence, must_contain=[], must_not_contain=[], must_not_contain_at=[]):\n",
    "    q = infer.query(variables, evidence=evidence, show_progress=False)\n",
    "    \n",
    "    count_predictions = len(q.values.flatten()[q.values.flatten() != 0])\n",
    "    max_value_indices = (-q.values.flatten()).argsort()[:count_predictions]\n",
    "\n",
    "    with open(\"wordle-at-words.json\", \"r\") as f:\n",
    "        words = json.load(f)\n",
    "        \n",
    "        for max_value_index in max_value_indices:\n",
    "            indices = np.unravel_index(max_value_index, q.values.shape)\n",
    "\n",
    "            suggestion = {}\n",
    "\n",
    "            for index, variable in enumerate(q.variables):\n",
    "                suggestion[variable] = model.get_cpds(variable).state_names[variable][indices[index]]\n",
    "\n",
    "            word = get_suggestion_word(suggestion, evidence)\n",
    "\n",
    "            if word_is_valid(word, words, must_contain, must_not_contain, must_not_contain_at):\n",
    "                return word\n",
    "            \n",
    "    return []\n",
    "\n",
    "def get_first_suggestion():\n",
    "    with open(\"wordle-at-words.json\", \"r\") as f:\n",
    "        words_json = json.load(f)\n",
    "\n",
    "    first = infer.map_query([\"first\"], show_progress=False)[\"first\"]\n",
    "    second = infer.map_query([\"second\"], evidence={\"first\": first}, show_progress=False)[\"second\"]\n",
    "    third = infer.map_query([\"third\"], evidence={\"first\": first, \"second\": second}, show_progress=False)[\"third\"]\n",
    "    forth = infer.map_query([\"forth\"], evidence={\"first\": first, \"second\": second, \"third\": third}, show_progress=False)[\"forth\"]\n",
    "    fifth = infer.map_query([\"fifth\"], evidence={\"first\": first, \"second\": second, \"third\": third, \"forth\": forth}, show_progress=False)[\"fifth\"]\n",
    "\n",
    "    if word_is_valid(\"\".join([first,second,third,forth,fifth]), words_json):\n",
    "        return \"\".join[first,second,third,forth,fifth]\n",
    "    elif len(words[\n",
    "            (words[\"first\"] == first) & \n",
    "            (words[\"second\"] == second) & \n",
    "            (words[\"third\"] == third) & \n",
    "            (words[\"forth\"] == forth)]) > 0:\n",
    "        return words[\n",
    "            (words[\"first\"] == first) & \n",
    "            (words[\"second\"] == second) & \n",
    "            (words[\"third\"] == third) & \n",
    "            (words[\"forth\"] == forth)].values[0]\n",
    "    else:\n",
    "        return words[\n",
    "            (words[\"first\"] == first) & \n",
    "            (words[\"second\"] == second) & \n",
    "            (words[\"third\"] == third)].values[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c39063",
   "metadata": {},
   "source": [
    "### 1st guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First guess: \" + \"\".join(get_first_suggestion()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755d1d75",
   "metadata": {},
   "source": [
    "### 2nd guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion = get_suggestion(\n",
    "    variables=[\"first\", \"second\", \"third\", \"forth\", \"fifth\"], \n",
    "    evidence={\n",
    "    }, \n",
    "    must_contain=[\"S\"],\n",
    "    must_not_contain=[\"A\", \"B\", \"O\", \"R\"], \n",
    "    must_not_contain_at={\n",
    "        \"first\":[\"S\"], \n",
    "        \"second\":[], \n",
    "        \"third\":[],\n",
    "        \"forth\":[],\n",
    "        \"fifth\":[]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Next guess: \" + \"\".join(suggestion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c8671",
   "metadata": {},
   "source": [
    "### 3rd guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfdb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion = get_suggestion(\n",
    "    variables=[\"first\", \"second\", \"third\", \"forth\", \"fifth\"], \n",
    "    evidence={\n",
    "    }, \n",
    "    must_contain=[\"S\", \"E\", \"I\"],\n",
    "    must_not_contain=[\"A\", \"B\", \"O\", \"R\", \"L\", \"N\"], \n",
    "    must_not_contain_at={\n",
    "        \"first\":[\"S\"], \n",
    "        \"second\":[\"E\"], \n",
    "        \"third\":[\"I\"],\n",
    "        \"forth\":[],\n",
    "        \"fifth\":[\"S\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Next guess: \" + \"\".join(suggestion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95258c",
   "metadata": {},
   "source": [
    "### 4th guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff7e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestion = get_suggestion(\n",
    "    variables=[\"first\"], \n",
    "    evidence={\n",
    "        \"second\": \"I\", \n",
    "        \"third\": \"S\", \n",
    "        \"forth\": \"T\", \n",
    "        \"fifth\": \"E\"\n",
    "    }, \n",
    "    must_contain=[\"S\", \"E\", \"I\"],\n",
    "    must_not_contain=[\"A\", \"B\", \"O\", \"R\", \"L\", \"N\", \"M\"], \n",
    "    must_not_contain_at={\n",
    "        \"first\":[\"S\"], \n",
    "        \"second\":[\"E\"], \n",
    "        \"third\":[\"I\"],\n",
    "        \"forth\":[],\n",
    "        \"fifth\":[\"S\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Next guess: \" + \"\".join(suggestion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
